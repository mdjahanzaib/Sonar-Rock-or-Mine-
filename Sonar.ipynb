{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sonar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdjahanzaib/Sonar-Rock-or-Mine-/blob/master/Sonar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2mt1v88IP4_",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Neural Network Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUOUdj3qBmKT",
        "colab_type": "code",
        "outputId": "131d8f05-d43d-4274-b23c-e4f4191c7d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from tensorflow.keras import models\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbVm5tsUCwq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ychflwMwC7SU",
        "colab_type": "code",
        "outputId": "91bedc96-b7c7-4358-809e-e24fd0f0c1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"sonar.csv\", header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "Y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_i3sdUUC__b",
        "colab_type": "code",
        "outputId": "9fd36e0c-09f1-4b58-b12c-be32cffa7fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder_op = LabelEncoder()\n",
        "encoded_Y=label_encoder_op.fit_transform(Y)\n",
        "encoded_Y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwIBjpwrBwO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbByOeaaGXTt",
        "colab_type": "code",
        "outputId": "b44c5052-6096-4a62-87df-3ffcd7e64e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(208, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axtja9ncDoBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_Y=label_encoder_op.fit_transform(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEa6e0fPDztS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline model\n",
        "def create_baseline():\n",
        "\t# create model, write code below\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(60,activation = 'relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  # Compile model, write code below\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uvp0qsfD0l9",
        "colab_type": "code",
        "outputId": "c8fccd60-3467-42a3-aac9-45b90f2c605e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# evaluate model with standardized dataset\n",
        "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Results: 83.64% (6.57%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuBmNKmZIZD1",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model With Data Preparation (Pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYU_t5u-HWbQ",
        "colab_type": "code",
        "outputId": "a131dabd-ec8b-4279-bd0e-2bfdea3c419f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate baseline model with standardized dataset\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized: 84.61% (6.35%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrlgAAa_Jqho",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate a Smaller Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6_oEq5wJuaf",
        "colab_type": "code",
        "outputId": "f442101f-a3c4-4942-fa4b-3ef0f89b8360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# smaller model\n",
        "def create_smaller():\n",
        "\t# create model\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(30,activation = 'relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smaller: 86.99% (5.34%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXW5SVq_MXKJ",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate a Larger Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK3DtphOMZ4t",
        "colab_type": "code",
        "outputId": "df5ca829-e638-4e91-e00c-318d91cca3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# larger model\n",
        "def create_larger():\n",
        "\t# create model\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(60,activation = 'relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(30, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Larger: 85.09% (3.98%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E25uSBEHO3M",
        "colab_type": "text"
      },
      "source": [
        "# Scaling up: Developing a model that overfits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5I7JqJoHSaX",
        "colab_type": "code",
        "outputId": "fc78a919-f954-4161-f08f-ddb7ed8c04a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def create_overfit():\n",
        "\t# create model\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(200,activation = 'relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(160, activation='relu'))\n",
        "  model.add(layers.Dense(130, activation='relu'))\n",
        "  model.add(layers.Dense(50, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_overfit, epochs=250, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print(\"Overfit: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overfit: 83.64% (4.35%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwitQWR-Lkk2",
        "colab_type": "text"
      },
      "source": [
        "# Tuning the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXEaHTYNHp8W",
        "colab_type": "code",
        "outputId": "3cf5feb0-44e7-4331-a859-8155728a3f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def create_best():\n",
        "\t# create model\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(60,activation = 'relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(30, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "  model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_best, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
        "print(\"Optimized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimized: 86.04% (5.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIJkTKZZQSDx",
        "colab_type": "text"
      },
      "source": [
        "# Rewriting the code without using scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dSMyh1jRBlO",
        "colab_type": "code",
        "outputId": "7bbba7e7-e4f3-4ae7-9e29-58cb2387fe37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# create model, write code below\n",
        "mean = X.mean(axis=0)\n",
        "X -= mean\n",
        "std = X.std(axis=0)\n",
        "X /= std\n",
        "def build_model():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(60,activation = 'relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "# Compile model, write code below\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "k = 10\n",
        "num_val_samples = len(X) // k\n",
        "num_epochs = 80\n",
        "all_mae_scores = []\n",
        "all_mse_scores = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = encoded_Y[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  partial_train_data = numpy.concatenate(\n",
        "  [X[:i * num_val_samples],\n",
        "  X[(i + 1) * num_val_samples:]],\n",
        "  axis=0)\n",
        "  partial_train_targets = numpy.concatenate(\n",
        "  [encoded_Y[:i * num_val_samples],\n",
        "  encoded_Y[(i + 1) * num_val_samples:]],\n",
        "  axis=0)\n",
        "  model = build_model()\n",
        "  model.fit(partial_train_data, partial_train_targets,\n",
        "  epochs=num_epochs, batch_size=10, verbose=1)\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
        "  all_mae_scores.append(val_mae)\n",
        "  all_mse_scores.append(val_mse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 5ms/sample - loss: 0.5444 - acc: 0.7606\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 523us/sample - loss: 0.4189 - acc: 0.8511\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 532us/sample - loss: 0.3543 - acc: 0.8883\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 420us/sample - loss: 0.3070 - acc: 0.9096\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 379us/sample - loss: 0.2723 - acc: 0.9255\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 306us/sample - loss: 0.2422 - acc: 0.9415\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 396us/sample - loss: 0.2169 - acc: 0.9468\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 692us/sample - loss: 0.1954 - acc: 0.9521\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 551us/sample - loss: 0.1763 - acc: 0.9628\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 481us/sample - loss: 0.1595 - acc: 0.9681\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 379us/sample - loss: 0.1476 - acc: 0.9681\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.1325 - acc: 0.9840\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 463us/sample - loss: 0.1210 - acc: 0.9894\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 351us/sample - loss: 0.1123 - acc: 0.9840\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.1023 - acc: 0.9947\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 450us/sample - loss: 0.0938 - acc: 0.9947\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 441us/sample - loss: 0.0865 - acc: 0.9947\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 436us/sample - loss: 0.0802 - acc: 0.9947\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 469us/sample - loss: 0.0735 - acc: 0.9947\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 550us/sample - loss: 0.0678 - acc: 0.9947\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 579us/sample - loss: 0.0632 - acc: 1.0000\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 446us/sample - loss: 0.0580 - acc: 1.0000\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 406us/sample - loss: 0.0545 - acc: 1.0000\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 600us/sample - loss: 0.0504 - acc: 1.0000\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 602us/sample - loss: 0.0473 - acc: 1.0000\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 548us/sample - loss: 0.0442 - acc: 1.0000\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 504us/sample - loss: 0.0402 - acc: 1.0000\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 523us/sample - loss: 0.0382 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 606us/sample - loss: 0.0352 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 639us/sample - loss: 0.0328 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 753us/sample - loss: 0.0307 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 571us/sample - loss: 0.0289 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 490us/sample - loss: 0.0270 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 684us/sample - loss: 0.0254 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 632us/sample - loss: 0.0241 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 542us/sample - loss: 0.0227 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 544us/sample - loss: 0.0214 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 492us/sample - loss: 0.0202 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 557us/sample - loss: 0.0191 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 504us/sample - loss: 0.0179 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 493us/sample - loss: 0.0173 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 509us/sample - loss: 0.0162 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 432us/sample - loss: 0.0155 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 418us/sample - loss: 0.0147 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 497us/sample - loss: 0.0139 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 575us/sample - loss: 0.0132 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 696us/sample - loss: 0.0127 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 427us/sample - loss: 0.0122 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 391us/sample - loss: 0.0116 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 457us/sample - loss: 0.0110 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 445us/sample - loss: 0.0105 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 446us/sample - loss: 0.0101 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 426us/sample - loss: 0.0097 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.0093 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 553us/sample - loss: 0.0089 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 661us/sample - loss: 0.0085 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 680us/sample - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 441us/sample - loss: 0.0079 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 454us/sample - loss: 0.0076 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 479us/sample - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 507us/sample - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 555us/sample - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 466us/sample - loss: 0.0065 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 389us/sample - loss: 0.0063 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 436us/sample - loss: 0.0061 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 538us/sample - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 511us/sample - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 469us/sample - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 450us/sample - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 337us/sample - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 537us/sample - loss: 0.0049 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 424us/sample - loss: 0.0048 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 431us/sample - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 391us/sample - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 447us/sample - loss: 0.0043 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 477us/sample - loss: 0.0042 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 550us/sample - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 682us/sample - loss: 0.0040 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 438us/sample - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 533us/sample - loss: 0.0037 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 39ms/sample - loss: 2.0475 - acc: 0.5500\n",
            "processing fold # 1\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 5ms/sample - loss: 0.6028 - acc: 0.6543\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 641us/sample - loss: 0.4616 - acc: 0.8351\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 559us/sample - loss: 0.3940 - acc: 0.8723\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 500us/sample - loss: 0.3461 - acc: 0.8830\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 629us/sample - loss: 0.3129 - acc: 0.8936\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 609us/sample - loss: 0.2799 - acc: 0.9096\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 569us/sample - loss: 0.2544 - acc: 0.9096\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 515us/sample - loss: 0.2305 - acc: 0.9415\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 571us/sample - loss: 0.2109 - acc: 0.9468\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 489us/sample - loss: 0.1915 - acc: 0.9521\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 544us/sample - loss: 0.1766 - acc: 0.9681\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 510us/sample - loss: 0.1615 - acc: 0.9734\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 459us/sample - loss: 0.1485 - acc: 0.9681\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 406us/sample - loss: 0.1370 - acc: 0.9734\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.1271 - acc: 0.9787\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 352us/sample - loss: 0.1170 - acc: 0.9894\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 428us/sample - loss: 0.1085 - acc: 0.9894\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 458us/sample - loss: 0.1004 - acc: 0.9894\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 498us/sample - loss: 0.0936 - acc: 0.9894\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 435us/sample - loss: 0.0868 - acc: 0.9947\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 353us/sample - loss: 0.0813 - acc: 0.9947\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 378us/sample - loss: 0.0748 - acc: 1.0000\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 384us/sample - loss: 0.0696 - acc: 1.0000\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 454us/sample - loss: 0.0650 - acc: 1.0000\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 544us/sample - loss: 0.0606 - acc: 1.0000\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 617us/sample - loss: 0.0574 - acc: 1.0000\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 563us/sample - loss: 0.0532 - acc: 1.0000\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 554us/sample - loss: 0.0496 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 499us/sample - loss: 0.0464 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 545us/sample - loss: 0.0435 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 546us/sample - loss: 0.0409 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 527us/sample - loss: 0.0387 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 539us/sample - loss: 0.0366 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 504us/sample - loss: 0.0344 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 642us/sample - loss: 0.0325 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 612us/sample - loss: 0.0307 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 603us/sample - loss: 0.0291 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 580us/sample - loss: 0.0273 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 541us/sample - loss: 0.0259 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 473us/sample - loss: 0.0246 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 511us/sample - loss: 0.0233 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 541us/sample - loss: 0.0222 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 442us/sample - loss: 0.0211 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 380us/sample - loss: 0.0200 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 388us/sample - loss: 0.0191 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 380us/sample - loss: 0.0183 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 333us/sample - loss: 0.0174 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 303us/sample - loss: 0.0165 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 471us/sample - loss: 0.0157 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 0.0152 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 441us/sample - loss: 0.0144 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 489us/sample - loss: 0.0138 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 389us/sample - loss: 0.0132 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 337us/sample - loss: 0.0126 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 480us/sample - loss: 0.0122 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 0.0116 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 441us/sample - loss: 0.0112 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 524us/sample - loss: 0.0107 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 404us/sample - loss: 0.0105 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 405us/sample - loss: 0.0100 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 398us/sample - loss: 0.0097 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 338us/sample - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 346us/sample - loss: 0.0089 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 348us/sample - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 336us/sample - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 357us/sample - loss: 0.0080 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 397us/sample - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 459us/sample - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 410us/sample - loss: 0.0072 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 383us/sample - loss: 0.0069 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 405us/sample - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 421us/sample - loss: 0.0065 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 397us/sample - loss: 0.0063 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 359us/sample - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 352us/sample - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 329us/sample - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 431us/sample - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 361us/sample - loss: 0.0051 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 40ms/sample - loss: 0.7945 - acc: 0.8500\n",
            "processing fold # 2\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 5ms/sample - loss: 0.7187 - acc: 0.5479\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 574us/sample - loss: 0.5577 - acc: 0.7021\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 682us/sample - loss: 0.4676 - acc: 0.7713\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 588us/sample - loss: 0.4037 - acc: 0.8245\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 587us/sample - loss: 0.3562 - acc: 0.8617\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 648us/sample - loss: 0.3155 - acc: 0.8830\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 593us/sample - loss: 0.2831 - acc: 0.9202\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 359us/sample - loss: 0.2541 - acc: 0.9362\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 455us/sample - loss: 0.2310 - acc: 0.9468\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 535us/sample - loss: 0.2109 - acc: 0.9521\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 432us/sample - loss: 0.1908 - acc: 0.9628\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 404us/sample - loss: 0.1741 - acc: 0.9628\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 490us/sample - loss: 0.1594 - acc: 0.9734\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 444us/sample - loss: 0.1454 - acc: 0.9787\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 507us/sample - loss: 0.1338 - acc: 0.9894\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 469us/sample - loss: 0.1232 - acc: 0.9894\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 507us/sample - loss: 0.1125 - acc: 0.9947\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 486us/sample - loss: 0.1037 - acc: 0.9947\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 442us/sample - loss: 0.0954 - acc: 0.9947\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 0.0890 - acc: 0.9947\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 434us/sample - loss: 0.0823 - acc: 1.0000\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 431us/sample - loss: 0.0758 - acc: 1.0000\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 375us/sample - loss: 0.0699 - acc: 1.0000\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 391us/sample - loss: 0.0647 - acc: 1.0000\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.0605 - acc: 1.0000\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 330us/sample - loss: 0.0559 - acc: 1.0000\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 384us/sample - loss: 0.0520 - acc: 1.0000\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.0485 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 366us/sample - loss: 0.0452 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 472us/sample - loss: 0.0423 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 412us/sample - loss: 0.0397 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 406us/sample - loss: 0.0376 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 374us/sample - loss: 0.0348 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 463us/sample - loss: 0.0329 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 445us/sample - loss: 0.0309 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 574us/sample - loss: 0.0290 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 547us/sample - loss: 0.0276 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 528us/sample - loss: 0.0260 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 397us/sample - loss: 0.0244 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 386us/sample - loss: 0.0230 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 402us/sample - loss: 0.0220 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 353us/sample - loss: 0.0208 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.0197 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 465us/sample - loss: 0.0188 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 495us/sample - loss: 0.0178 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 508us/sample - loss: 0.0170 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 400us/sample - loss: 0.0162 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 385us/sample - loss: 0.0155 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 345us/sample - loss: 0.0147 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.0141 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 328us/sample - loss: 0.0136 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 458us/sample - loss: 0.0129 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 435us/sample - loss: 0.0124 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.0118 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 333us/sample - loss: 0.0114 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 416us/sample - loss: 0.0110 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 412us/sample - loss: 0.0105 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 393us/sample - loss: 0.0101 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 430us/sample - loss: 0.0097 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 430us/sample - loss: 0.0093 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 446us/sample - loss: 0.0090 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 392us/sample - loss: 0.0087 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 461us/sample - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 388us/sample - loss: 0.0081 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 455us/sample - loss: 0.0078 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 552us/sample - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 364us/sample - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 407us/sample - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 416us/sample - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 454us/sample - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 490us/sample - loss: 0.0064 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 565us/sample - loss: 0.0061 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 415us/sample - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 448us/sample - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 365us/sample - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 374us/sample - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 419us/sample - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 504us/sample - loss: 0.0051 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 431us/sample - loss: 0.0050 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 393us/sample - loss: 0.0049 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 41ms/sample - loss: 1.6055 - acc: 0.6000\n",
            "processing fold # 3\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 5ms/sample - loss: 0.7804 - acc: 0.5585\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 548us/sample - loss: 0.5545 - acc: 0.7447\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 527us/sample - loss: 0.4747 - acc: 0.7713\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 540us/sample - loss: 0.4210 - acc: 0.8191\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 499us/sample - loss: 0.3811 - acc: 0.8404\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 472us/sample - loss: 0.3482 - acc: 0.8617\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 389us/sample - loss: 0.3234 - acc: 0.8777\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 423us/sample - loss: 0.2947 - acc: 0.8989\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.2725 - acc: 0.9255\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 443us/sample - loss: 0.2517 - acc: 0.9255\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 394us/sample - loss: 0.2323 - acc: 0.9468\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.2150 - acc: 0.9468\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 403us/sample - loss: 0.1988 - acc: 0.9574\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 478us/sample - loss: 0.1843 - acc: 0.9681\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 523us/sample - loss: 0.1704 - acc: 0.9787\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 417us/sample - loss: 0.1584 - acc: 0.9840\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 433us/sample - loss: 0.1488 - acc: 0.9840\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 406us/sample - loss: 0.1375 - acc: 0.9947\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 484us/sample - loss: 0.1277 - acc: 0.9894\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 400us/sample - loss: 0.1182 - acc: 1.0000\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 509us/sample - loss: 0.1105 - acc: 1.0000\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 469us/sample - loss: 0.1032 - acc: 1.0000\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 409us/sample - loss: 0.0961 - acc: 1.0000\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 397us/sample - loss: 0.0900 - acc: 1.0000\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 417us/sample - loss: 0.0837 - acc: 1.0000\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 408us/sample - loss: 0.0784 - acc: 1.0000\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 341us/sample - loss: 0.0735 - acc: 1.0000\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 410us/sample - loss: 0.0684 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 400us/sample - loss: 0.0640 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 381us/sample - loss: 0.0604 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 392us/sample - loss: 0.0571 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 555us/sample - loss: 0.0534 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 468us/sample - loss: 0.0503 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 414us/sample - loss: 0.0476 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 457us/sample - loss: 0.0447 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 347us/sample - loss: 0.0417 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 366us/sample - loss: 0.0397 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 487us/sample - loss: 0.0374 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 433us/sample - loss: 0.0355 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 716us/sample - loss: 0.0335 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 690us/sample - loss: 0.0319 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 614us/sample - loss: 0.0301 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 470us/sample - loss: 0.0289 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 488us/sample - loss: 0.0273 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 478us/sample - loss: 0.0259 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 389us/sample - loss: 0.0246 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 447us/sample - loss: 0.0235 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 388us/sample - loss: 0.0224 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 585us/sample - loss: 0.0214 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 704us/sample - loss: 0.0205 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 535us/sample - loss: 0.0195 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 463us/sample - loss: 0.0187 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 520us/sample - loss: 0.0180 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 636us/sample - loss: 0.0172 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 488us/sample - loss: 0.0165 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 450us/sample - loss: 0.0158 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 463us/sample - loss: 0.0151 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 440us/sample - loss: 0.0145 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 442us/sample - loss: 0.0139 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 461us/sample - loss: 0.0134 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 494us/sample - loss: 0.0130 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 582us/sample - loss: 0.0124 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 468us/sample - loss: 0.0119 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 457us/sample - loss: 0.0116 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 451us/sample - loss: 0.0111 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 372us/sample - loss: 0.0108 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.0104 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 402us/sample - loss: 0.0100 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 0.0097 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 482us/sample - loss: 0.0090 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 409us/sample - loss: 0.0087 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 424us/sample - loss: 0.0084 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 381us/sample - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 394us/sample - loss: 0.0079 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 415us/sample - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 408us/sample - loss: 0.0074 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 406us/sample - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 427us/sample - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 437us/sample - loss: 0.0068 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 41ms/sample - loss: 0.1456 - acc: 0.8500\n",
            "processing fold # 4\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 5ms/sample - loss: 0.8598 - acc: 0.4362\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 521us/sample - loss: 0.5611 - acc: 0.7234\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 502us/sample - loss: 0.4426 - acc: 0.8245\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 524us/sample - loss: 0.3733 - acc: 0.8617\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 592us/sample - loss: 0.3278 - acc: 0.8830\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 555us/sample - loss: 0.2903 - acc: 0.9202\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 568us/sample - loss: 0.2582 - acc: 0.9362\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 540us/sample - loss: 0.2348 - acc: 0.9468\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 377us/sample - loss: 0.2106 - acc: 0.9628\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 500us/sample - loss: 0.1909 - acc: 0.9628\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 566us/sample - loss: 0.1741 - acc: 0.9628\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 600us/sample - loss: 0.1604 - acc: 0.9681\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 543us/sample - loss: 0.1472 - acc: 0.9787\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 442us/sample - loss: 0.1362 - acc: 0.9840\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 452us/sample - loss: 0.1259 - acc: 0.9894\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 467us/sample - loss: 0.1153 - acc: 0.9894\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 472us/sample - loss: 0.1072 - acc: 0.9894\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 620us/sample - loss: 0.0998 - acc: 0.9947\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 675us/sample - loss: 0.0925 - acc: 0.9947\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 654us/sample - loss: 0.0861 - acc: 1.0000\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 704us/sample - loss: 0.0806 - acc: 1.0000\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 694us/sample - loss: 0.0762 - acc: 0.9947\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 667us/sample - loss: 0.0705 - acc: 1.0000\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 641us/sample - loss: 0.0650 - acc: 1.0000\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 544us/sample - loss: 0.0609 - acc: 1.0000\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 449us/sample - loss: 0.0572 - acc: 1.0000\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 451us/sample - loss: 0.0538 - acc: 1.0000\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 518us/sample - loss: 0.0504 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 489us/sample - loss: 0.0477 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 656us/sample - loss: 0.0450 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 668us/sample - loss: 0.0420 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 470us/sample - loss: 0.0400 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 422us/sample - loss: 0.0378 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 628us/sample - loss: 0.0356 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 584us/sample - loss: 0.0336 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 564us/sample - loss: 0.0316 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 564us/sample - loss: 0.0301 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 556us/sample - loss: 0.0284 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 633us/sample - loss: 0.0270 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 649us/sample - loss: 0.0256 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 655us/sample - loss: 0.0244 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 621us/sample - loss: 0.0231 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 661us/sample - loss: 0.0220 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 685us/sample - loss: 0.0210 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 648us/sample - loss: 0.0200 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 669us/sample - loss: 0.0190 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 650us/sample - loss: 0.0182 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 659us/sample - loss: 0.0174 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 615us/sample - loss: 0.0166 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 568us/sample - loss: 0.0159 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 581us/sample - loss: 0.0152 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 640us/sample - loss: 0.0149 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 609us/sample - loss: 0.0140 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 594us/sample - loss: 0.0136 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 554us/sample - loss: 0.0129 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 581us/sample - loss: 0.0124 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 546us/sample - loss: 0.0120 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 561us/sample - loss: 0.0115 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 457us/sample - loss: 0.0110 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 483us/sample - loss: 0.0107 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 443us/sample - loss: 0.0104 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 539us/sample - loss: 0.0098 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 582us/sample - loss: 0.0096 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 492us/sample - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 405us/sample - loss: 0.0089 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 468us/sample - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 494us/sample - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 421us/sample - loss: 0.0080 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 595us/sample - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 695us/sample - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 694us/sample - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 580us/sample - loss: 0.0071 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 665us/sample - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 564us/sample - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 599us/sample - loss: 0.0064 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 438us/sample - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 557us/sample - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 555us/sample - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 556us/sample - loss: 0.0057 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 586us/sample - loss: 0.0055 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 45ms/sample - loss: 1.7481 - acc: 0.5500\n",
            "processing fold # 5\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 5ms/sample - loss: 0.7811 - acc: 0.5798\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.5293 - acc: 0.7340\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 468us/sample - loss: 0.4257 - acc: 0.8351\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 468us/sample - loss: 0.3649 - acc: 0.8617\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 593us/sample - loss: 0.3198 - acc: 0.8777\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 513us/sample - loss: 0.2834 - acc: 0.9096\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 529us/sample - loss: 0.2551 - acc: 0.9149\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 428us/sample - loss: 0.2312 - acc: 0.9255\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 635us/sample - loss: 0.2104 - acc: 0.9362\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 587us/sample - loss: 0.1936 - acc: 0.9521\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 552us/sample - loss: 0.1771 - acc: 0.9574\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 549us/sample - loss: 0.1632 - acc: 0.9574\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 709us/sample - loss: 0.1500 - acc: 0.9628\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 562us/sample - loss: 0.1386 - acc: 0.9734\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 567us/sample - loss: 0.1289 - acc: 0.9894\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 580us/sample - loss: 0.1190 - acc: 0.9894\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 500us/sample - loss: 0.1105 - acc: 0.9947\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 478us/sample - loss: 0.1020 - acc: 0.9947\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 464us/sample - loss: 0.0948 - acc: 0.9947\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 479us/sample - loss: 0.0870 - acc: 0.9947\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 660us/sample - loss: 0.0819 - acc: 0.9947\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 687us/sample - loss: 0.0756 - acc: 0.9947\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 590us/sample - loss: 0.0707 - acc: 0.9947\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 547us/sample - loss: 0.0655 - acc: 0.9947\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 634us/sample - loss: 0.0610 - acc: 0.9947\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 481us/sample - loss: 0.0576 - acc: 1.0000\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 517us/sample - loss: 0.0539 - acc: 1.0000\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 536us/sample - loss: 0.0507 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 543us/sample - loss: 0.0472 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 584us/sample - loss: 0.0444 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 518us/sample - loss: 0.0413 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 544us/sample - loss: 0.0389 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 478us/sample - loss: 0.0367 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 436us/sample - loss: 0.0349 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 497us/sample - loss: 0.0323 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 570us/sample - loss: 0.0309 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 480us/sample - loss: 0.0294 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 583us/sample - loss: 0.0274 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 556us/sample - loss: 0.0259 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 539us/sample - loss: 0.0244 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 580us/sample - loss: 0.0234 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 539us/sample - loss: 0.0221 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 553us/sample - loss: 0.0208 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 542us/sample - loss: 0.0198 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 568us/sample - loss: 0.0192 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 562us/sample - loss: 0.0182 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 609us/sample - loss: 0.0175 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 722us/sample - loss: 0.0164 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 691us/sample - loss: 0.0157 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 659us/sample - loss: 0.0151 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 712us/sample - loss: 0.0146 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 671us/sample - loss: 0.0138 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 677us/sample - loss: 0.0133 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 602us/sample - loss: 0.0127 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 535us/sample - loss: 0.0122 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 595us/sample - loss: 0.0117 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 693us/sample - loss: 0.0113 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 487us/sample - loss: 0.0107 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 455us/sample - loss: 0.0104 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 491us/sample - loss: 0.0099 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 484us/sample - loss: 0.0096 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 414us/sample - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 477us/sample - loss: 0.0089 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 484us/sample - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 547us/sample - loss: 0.0084 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 586us/sample - loss: 0.0080 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 528us/sample - loss: 0.0078 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 500us/sample - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 564us/sample - loss: 0.0072 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 528us/sample - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 528us/sample - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 503us/sample - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 501us/sample - loss: 0.0064 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 508us/sample - loss: 0.0061 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 632us/sample - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 555us/sample - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 462us/sample - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 737us/sample - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 566us/sample - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 580us/sample - loss: 0.0051 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 40ms/sample - loss: 1.9152 - acc: 0.5000\n",
            "processing fold # 6\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 6ms/sample - loss: 0.6477 - acc: 0.6330\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 654us/sample - loss: 0.5135 - acc: 0.7766\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 644us/sample - loss: 0.4387 - acc: 0.8085\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 654us/sample - loss: 0.3831 - acc: 0.8457\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 612us/sample - loss: 0.3429 - acc: 0.8883\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 574us/sample - loss: 0.3089 - acc: 0.9043\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 493us/sample - loss: 0.2804 - acc: 0.9255\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 474us/sample - loss: 0.2551 - acc: 0.9362\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 402us/sample - loss: 0.2335 - acc: 0.9468\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 483us/sample - loss: 0.2131 - acc: 0.9574\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.1965 - acc: 0.9574\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 385us/sample - loss: 0.1811 - acc: 0.9628\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 445us/sample - loss: 0.1680 - acc: 0.9787\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 543us/sample - loss: 0.1544 - acc: 0.9840\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 478us/sample - loss: 0.1427 - acc: 0.9894\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 404us/sample - loss: 0.1326 - acc: 0.9894\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 524us/sample - loss: 0.1231 - acc: 0.9947\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 606us/sample - loss: 0.1148 - acc: 0.9947\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 531us/sample - loss: 0.1065 - acc: 0.9947\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 575us/sample - loss: 0.0990 - acc: 0.9947\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 537us/sample - loss: 0.0923 - acc: 0.9947\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 564us/sample - loss: 0.0857 - acc: 0.9947\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 510us/sample - loss: 0.0803 - acc: 0.9947\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 513us/sample - loss: 0.0747 - acc: 0.9947\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 543us/sample - loss: 0.0697 - acc: 0.9947\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 588us/sample - loss: 0.0650 - acc: 0.9947\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 604us/sample - loss: 0.0615 - acc: 0.9947\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 599us/sample - loss: 0.0574 - acc: 0.9947\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 589us/sample - loss: 0.0540 - acc: 0.9947\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 607us/sample - loss: 0.0505 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 586us/sample - loss: 0.0476 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 530us/sample - loss: 0.0449 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 560us/sample - loss: 0.0433 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 578us/sample - loss: 0.0399 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 573us/sample - loss: 0.0372 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 582us/sample - loss: 0.0353 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 582us/sample - loss: 0.0333 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 580us/sample - loss: 0.0312 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 604us/sample - loss: 0.0299 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 578us/sample - loss: 0.0280 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 635us/sample - loss: 0.0267 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 518us/sample - loss: 0.0252 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 684us/sample - loss: 0.0239 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 532us/sample - loss: 0.0227 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 549us/sample - loss: 0.0218 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 513us/sample - loss: 0.0207 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 534us/sample - loss: 0.0196 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 532us/sample - loss: 0.0188 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 515us/sample - loss: 0.0178 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 664us/sample - loss: 0.0171 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 592us/sample - loss: 0.0164 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 688us/sample - loss: 0.0157 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 552us/sample - loss: 0.0149 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 647us/sample - loss: 0.0144 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 539us/sample - loss: 0.0137 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 737us/sample - loss: 0.0131 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 513us/sample - loss: 0.0126 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 437us/sample - loss: 0.0122 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 404us/sample - loss: 0.0117 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.0112 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 421us/sample - loss: 0.0109 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 572us/sample - loss: 0.0104 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 552us/sample - loss: 0.0101 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 542us/sample - loss: 0.0097 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 578us/sample - loss: 0.0093 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 595us/sample - loss: 0.0090 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 591us/sample - loss: 0.0087 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 561us/sample - loss: 0.0084 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 569us/sample - loss: 0.0081 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 582us/sample - loss: 0.0078 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 537us/sample - loss: 0.0076 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 601us/sample - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 558us/sample - loss: 0.0071 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 599us/sample - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 576us/sample - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 594us/sample - loss: 0.0064 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 531us/sample - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 543us/sample - loss: 0.0061 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 611us/sample - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 646us/sample - loss: 0.0057 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 53ms/sample - loss: 1.5338 - acc: 0.6500\n",
            "processing fold # 7\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 6ms/sample - loss: 0.7495 - acc: 0.5585\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 544us/sample - loss: 0.5390 - acc: 0.7553\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 559us/sample - loss: 0.4427 - acc: 0.8245\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 574us/sample - loss: 0.3800 - acc: 0.8830\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 557us/sample - loss: 0.3292 - acc: 0.8989\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 530us/sample - loss: 0.2902 - acc: 0.9255\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 587us/sample - loss: 0.2579 - acc: 0.9415\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 590us/sample - loss: 0.2319 - acc: 0.9681\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 646us/sample - loss: 0.2092 - acc: 0.9734\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 666us/sample - loss: 0.1878 - acc: 0.9628\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 604us/sample - loss: 0.1709 - acc: 0.9681\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 582us/sample - loss: 0.1579 - acc: 0.9734\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 573us/sample - loss: 0.1430 - acc: 0.9734\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 577us/sample - loss: 0.1301 - acc: 0.9840\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 584us/sample - loss: 0.1179 - acc: 0.9894\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 560us/sample - loss: 0.1094 - acc: 0.9947\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 634us/sample - loss: 0.1001 - acc: 1.0000\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 654us/sample - loss: 0.0923 - acc: 0.9947\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 647us/sample - loss: 0.0857 - acc: 0.9947\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 563us/sample - loss: 0.0789 - acc: 1.0000\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 660us/sample - loss: 0.0725 - acc: 1.0000\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 669us/sample - loss: 0.0676 - acc: 1.0000\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 583us/sample - loss: 0.0625 - acc: 1.0000\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 583us/sample - loss: 0.0585 - acc: 1.0000\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 542us/sample - loss: 0.0544 - acc: 1.0000\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 551us/sample - loss: 0.0507 - acc: 1.0000\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 568us/sample - loss: 0.0473 - acc: 1.0000\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 577us/sample - loss: 0.0443 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 626us/sample - loss: 0.0416 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 584us/sample - loss: 0.0386 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 574us/sample - loss: 0.0363 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 554us/sample - loss: 0.0346 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 551us/sample - loss: 0.0324 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 535us/sample - loss: 0.0305 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 536us/sample - loss: 0.0288 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 562us/sample - loss: 0.0273 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 530us/sample - loss: 0.0258 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 548us/sample - loss: 0.0245 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 552us/sample - loss: 0.0231 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 560us/sample - loss: 0.0220 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 539us/sample - loss: 0.0207 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 527us/sample - loss: 0.0199 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 573us/sample - loss: 0.0189 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 455us/sample - loss: 0.0180 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 470us/sample - loss: 0.0172 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 584us/sample - loss: 0.0163 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 516us/sample - loss: 0.0156 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 684us/sample - loss: 0.0149 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 497us/sample - loss: 0.0142 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 466us/sample - loss: 0.0137 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 475us/sample - loss: 0.0131 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 430us/sample - loss: 0.0124 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 483us/sample - loss: 0.0119 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 533us/sample - loss: 0.0115 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 549us/sample - loss: 0.0110 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 507us/sample - loss: 0.0105 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 514us/sample - loss: 0.0101 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 620us/sample - loss: 0.0097 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 518us/sample - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 591us/sample - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 525us/sample - loss: 0.0087 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 655us/sample - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 593us/sample - loss: 0.0081 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 612us/sample - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 451us/sample - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 465us/sample - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 528us/sample - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 464us/sample - loss: 0.0067 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 386us/sample - loss: 0.0065 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 370us/sample - loss: 0.0063 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 397us/sample - loss: 0.0061 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 457us/sample - loss: 0.0059 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 587us/sample - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 616us/sample - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 552us/sample - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 578us/sample - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 650us/sample - loss: 0.0051 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 662us/sample - loss: 0.0049 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 584us/sample - loss: 0.0048 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 584us/sample - loss: 0.0046 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 42ms/sample - loss: 2.7421 - acc: 0.6500\n",
            "processing fold # 8\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 6ms/sample - loss: 0.5491 - acc: 0.6862\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 583us/sample - loss: 0.4369 - acc: 0.7819\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 583us/sample - loss: 0.3750 - acc: 0.8511\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 568us/sample - loss: 0.3319 - acc: 0.8936\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 657us/sample - loss: 0.2938 - acc: 0.9149\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 608us/sample - loss: 0.2635 - acc: 0.9255\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 587us/sample - loss: 0.2393 - acc: 0.9309\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 578us/sample - loss: 0.2120 - acc: 0.9628\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 558us/sample - loss: 0.1936 - acc: 0.9787\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 413us/sample - loss: 0.1773 - acc: 0.9734\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 382us/sample - loss: 0.1595 - acc: 0.9840\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 508us/sample - loss: 0.1458 - acc: 0.9894\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 450us/sample - loss: 0.1334 - acc: 0.9894\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 540us/sample - loss: 0.1221 - acc: 0.9947\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 522us/sample - loss: 0.1106 - acc: 0.9947\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 383us/sample - loss: 0.1026 - acc: 0.9947\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 429us/sample - loss: 0.0938 - acc: 0.9947\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 422us/sample - loss: 0.0862 - acc: 1.0000\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 429us/sample - loss: 0.0789 - acc: 1.0000\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 648us/sample - loss: 0.0730 - acc: 1.0000\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 606us/sample - loss: 0.0675 - acc: 1.0000\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 580us/sample - loss: 0.0625 - acc: 1.0000\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 611us/sample - loss: 0.0578 - acc: 1.0000\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 599us/sample - loss: 0.0537 - acc: 1.0000\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 571us/sample - loss: 0.0496 - acc: 1.0000\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 582us/sample - loss: 0.0464 - acc: 1.0000\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 629us/sample - loss: 0.0429 - acc: 1.0000\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 561us/sample - loss: 0.0401 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 585us/sample - loss: 0.0375 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 591us/sample - loss: 0.0350 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 608us/sample - loss: 0.0328 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 603us/sample - loss: 0.0308 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 623us/sample - loss: 0.0287 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 592us/sample - loss: 0.0270 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 573us/sample - loss: 0.0253 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 581us/sample - loss: 0.0240 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 603us/sample - loss: 0.0225 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 536us/sample - loss: 0.0211 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 554us/sample - loss: 0.0200 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 529us/sample - loss: 0.0189 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 583us/sample - loss: 0.0180 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 585us/sample - loss: 0.0170 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 581us/sample - loss: 0.0161 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 588us/sample - loss: 0.0153 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 576us/sample - loss: 0.0145 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 600us/sample - loss: 0.0139 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 591us/sample - loss: 0.0132 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 640us/sample - loss: 0.0127 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 611us/sample - loss: 0.0120 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 577us/sample - loss: 0.0114 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 592us/sample - loss: 0.0109 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 581us/sample - loss: 0.0104 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 564us/sample - loss: 0.0100 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 573us/sample - loss: 0.0096 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 607us/sample - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 532us/sample - loss: 0.0088 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 546us/sample - loss: 0.0084 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 535us/sample - loss: 0.0081 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 556us/sample - loss: 0.0078 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 569us/sample - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 558us/sample - loss: 0.0072 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 579us/sample - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 527us/sample - loss: 0.0067 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 591us/sample - loss: 0.0065 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 580us/sample - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 594us/sample - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 575us/sample - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 537us/sample - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 561us/sample - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 519us/sample - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 601us/sample - loss: 0.0051 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 598us/sample - loss: 0.0049 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 628us/sample - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 598us/sample - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 638us/sample - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 620us/sample - loss: 0.0043 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 559us/sample - loss: 0.0042 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 604us/sample - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 546us/sample - loss: 0.0039 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 565us/sample - loss: 0.0038 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 42ms/sample - loss: 2.9256 - acc: 0.5000\n",
            "processing fold # 9\n",
            "Train on 188 samples\n",
            "Epoch 1/80\n",
            "188/188 [==============================] - 1s 5ms/sample - loss: 0.6205 - acc: 0.6809\n",
            "Epoch 2/80\n",
            "188/188 [==============================] - 0s 539us/sample - loss: 0.4940 - acc: 0.7447\n",
            "Epoch 3/80\n",
            "188/188 [==============================] - 0s 484us/sample - loss: 0.4272 - acc: 0.8032\n",
            "Epoch 4/80\n",
            "188/188 [==============================] - 0s 409us/sample - loss: 0.3779 - acc: 0.8617\n",
            "Epoch 5/80\n",
            "188/188 [==============================] - 0s 497us/sample - loss: 0.3379 - acc: 0.8723\n",
            "Epoch 6/80\n",
            "188/188 [==============================] - 0s 490us/sample - loss: 0.3051 - acc: 0.8936\n",
            "Epoch 7/80\n",
            "188/188 [==============================] - 0s 478us/sample - loss: 0.2748 - acc: 0.9202\n",
            "Epoch 8/80\n",
            "188/188 [==============================] - 0s 423us/sample - loss: 0.2494 - acc: 0.9255\n",
            "Epoch 9/80\n",
            "188/188 [==============================] - 0s 448us/sample - loss: 0.2263 - acc: 0.9362\n",
            "Epoch 10/80\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.2075 - acc: 0.9628\n",
            "Epoch 11/80\n",
            "188/188 [==============================] - 0s 425us/sample - loss: 0.1874 - acc: 0.9787\n",
            "Epoch 12/80\n",
            "188/188 [==============================] - 0s 518us/sample - loss: 0.1729 - acc: 0.9840\n",
            "Epoch 13/80\n",
            "188/188 [==============================] - 0s 615us/sample - loss: 0.1578 - acc: 0.9894\n",
            "Epoch 14/80\n",
            "188/188 [==============================] - 0s 490us/sample - loss: 0.1455 - acc: 0.9894\n",
            "Epoch 15/80\n",
            "188/188 [==============================] - 0s 444us/sample - loss: 0.1329 - acc: 0.9947\n",
            "Epoch 16/80\n",
            "188/188 [==============================] - 0s 366us/sample - loss: 0.1235 - acc: 0.9947\n",
            "Epoch 17/80\n",
            "188/188 [==============================] - 0s 413us/sample - loss: 0.1130 - acc: 0.9947\n",
            "Epoch 18/80\n",
            "188/188 [==============================] - 0s 447us/sample - loss: 0.1047 - acc: 0.9947\n",
            "Epoch 19/80\n",
            "188/188 [==============================] - 0s 403us/sample - loss: 0.0968 - acc: 0.9947\n",
            "Epoch 20/80\n",
            "188/188 [==============================] - 0s 604us/sample - loss: 0.0895 - acc: 0.9947\n",
            "Epoch 21/80\n",
            "188/188 [==============================] - 0s 419us/sample - loss: 0.0835 - acc: 0.9947\n",
            "Epoch 22/80\n",
            "188/188 [==============================] - 0s 370us/sample - loss: 0.0779 - acc: 0.9947\n",
            "Epoch 23/80\n",
            "188/188 [==============================] - 0s 417us/sample - loss: 0.0719 - acc: 0.9947\n",
            "Epoch 24/80\n",
            "188/188 [==============================] - 0s 641us/sample - loss: 0.0663 - acc: 0.9947\n",
            "Epoch 25/80\n",
            "188/188 [==============================] - 0s 582us/sample - loss: 0.0616 - acc: 0.9947\n",
            "Epoch 26/80\n",
            "188/188 [==============================] - 0s 663us/sample - loss: 0.0576 - acc: 0.9947\n",
            "Epoch 27/80\n",
            "188/188 [==============================] - 0s 577us/sample - loss: 0.0537 - acc: 0.9947\n",
            "Epoch 28/80\n",
            "188/188 [==============================] - 0s 556us/sample - loss: 0.0501 - acc: 1.0000\n",
            "Epoch 29/80\n",
            "188/188 [==============================] - 0s 562us/sample - loss: 0.0471 - acc: 1.0000\n",
            "Epoch 30/80\n",
            "188/188 [==============================] - 0s 524us/sample - loss: 0.0442 - acc: 1.0000\n",
            "Epoch 31/80\n",
            "188/188 [==============================] - 0s 579us/sample - loss: 0.0415 - acc: 1.0000\n",
            "Epoch 32/80\n",
            "188/188 [==============================] - 0s 553us/sample - loss: 0.0393 - acc: 1.0000\n",
            "Epoch 33/80\n",
            "188/188 [==============================] - 0s 546us/sample - loss: 0.0369 - acc: 1.0000\n",
            "Epoch 34/80\n",
            "188/188 [==============================] - 0s 548us/sample - loss: 0.0345 - acc: 1.0000\n",
            "Epoch 35/80\n",
            "188/188 [==============================] - 0s 569us/sample - loss: 0.0326 - acc: 1.0000\n",
            "Epoch 36/80\n",
            "188/188 [==============================] - 0s 576us/sample - loss: 0.0308 - acc: 1.0000\n",
            "Epoch 37/80\n",
            "188/188 [==============================] - 0s 538us/sample - loss: 0.0291 - acc: 1.0000\n",
            "Epoch 38/80\n",
            "188/188 [==============================] - 0s 641us/sample - loss: 0.0277 - acc: 1.0000\n",
            "Epoch 39/80\n",
            "188/188 [==============================] - 0s 618us/sample - loss: 0.0262 - acc: 1.0000\n",
            "Epoch 40/80\n",
            "188/188 [==============================] - 0s 581us/sample - loss: 0.0245 - acc: 1.0000\n",
            "Epoch 41/80\n",
            "188/188 [==============================] - 0s 579us/sample - loss: 0.0233 - acc: 1.0000\n",
            "Epoch 42/80\n",
            "188/188 [==============================] - 0s 546us/sample - loss: 0.0224 - acc: 1.0000\n",
            "Epoch 43/80\n",
            "188/188 [==============================] - 0s 501us/sample - loss: 0.0212 - acc: 1.0000\n",
            "Epoch 44/80\n",
            "188/188 [==============================] - 0s 513us/sample - loss: 0.0202 - acc: 1.0000\n",
            "Epoch 45/80\n",
            "188/188 [==============================] - 0s 540us/sample - loss: 0.0190 - acc: 1.0000\n",
            "Epoch 46/80\n",
            "188/188 [==============================] - 0s 550us/sample - loss: 0.0182 - acc: 1.0000\n",
            "Epoch 47/80\n",
            "188/188 [==============================] - 0s 568us/sample - loss: 0.0174 - acc: 1.0000\n",
            "Epoch 48/80\n",
            "188/188 [==============================] - 0s 541us/sample - loss: 0.0167 - acc: 1.0000\n",
            "Epoch 49/80\n",
            "188/188 [==============================] - 0s 538us/sample - loss: 0.0159 - acc: 1.0000\n",
            "Epoch 50/80\n",
            "188/188 [==============================] - 0s 595us/sample - loss: 0.0152 - acc: 1.0000\n",
            "Epoch 51/80\n",
            "188/188 [==============================] - 0s 602us/sample - loss: 0.0146 - acc: 1.0000\n",
            "Epoch 52/80\n",
            "188/188 [==============================] - 0s 675us/sample - loss: 0.0139 - acc: 1.0000\n",
            "Epoch 53/80\n",
            "188/188 [==============================] - 0s 684us/sample - loss: 0.0133 - acc: 1.0000\n",
            "Epoch 54/80\n",
            "188/188 [==============================] - 0s 660us/sample - loss: 0.0128 - acc: 1.0000\n",
            "Epoch 55/80\n",
            "188/188 [==============================] - 0s 644us/sample - loss: 0.0122 - acc: 1.0000\n",
            "Epoch 56/80\n",
            "188/188 [==============================] - 0s 659us/sample - loss: 0.0117 - acc: 1.0000\n",
            "Epoch 57/80\n",
            "188/188 [==============================] - 0s 585us/sample - loss: 0.0113 - acc: 1.0000\n",
            "Epoch 58/80\n",
            "188/188 [==============================] - 0s 662us/sample - loss: 0.0108 - acc: 1.0000\n",
            "Epoch 59/80\n",
            "188/188 [==============================] - 0s 554us/sample - loss: 0.0105 - acc: 1.0000\n",
            "Epoch 60/80\n",
            "188/188 [==============================] - 0s 615us/sample - loss: 0.0100 - acc: 1.0000\n",
            "Epoch 61/80\n",
            "188/188 [==============================] - 0s 555us/sample - loss: 0.0096 - acc: 1.0000\n",
            "Epoch 62/80\n",
            "188/188 [==============================] - 0s 536us/sample - loss: 0.0093 - acc: 1.0000\n",
            "Epoch 63/80\n",
            "188/188 [==============================] - 0s 592us/sample - loss: 0.0089 - acc: 1.0000\n",
            "Epoch 64/80\n",
            "188/188 [==============================] - 0s 562us/sample - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 65/80\n",
            "188/188 [==============================] - 0s 611us/sample - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 66/80\n",
            "188/188 [==============================] - 0s 524us/sample - loss: 0.0080 - acc: 1.0000\n",
            "Epoch 67/80\n",
            "188/188 [==============================] - 0s 558us/sample - loss: 0.0078 - acc: 1.0000\n",
            "Epoch 68/80\n",
            "188/188 [==============================] - 0s 494us/sample - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 69/80\n",
            "188/188 [==============================] - 0s 536us/sample - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 70/80\n",
            "188/188 [==============================] - 0s 575us/sample - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 71/80\n",
            "188/188 [==============================] - 0s 551us/sample - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 72/80\n",
            "188/188 [==============================] - 0s 549us/sample - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 73/80\n",
            "188/188 [==============================] - 0s 656us/sample - loss: 0.0064 - acc: 1.0000\n",
            "Epoch 74/80\n",
            "188/188 [==============================] - 0s 613us/sample - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 75/80\n",
            "188/188 [==============================] - 0s 691us/sample - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 76/80\n",
            "188/188 [==============================] - 0s 671us/sample - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 77/80\n",
            "188/188 [==============================] - 0s 681us/sample - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 78/80\n",
            "188/188 [==============================] - 0s 661us/sample - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 79/80\n",
            "188/188 [==============================] - 0s 560us/sample - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 80/80\n",
            "188/188 [==============================] - 0s 574us/sample - loss: 0.0051 - acc: 1.0000\n",
            "20/20 [==============================] - 1s 43ms/sample - loss: 0.0279 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7xFbOC9TV0s",
        "colab_type": "code",
        "outputId": "a39edbab-24fb-4150-97d8-c921cf662578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "all_mae_scores,all_mse_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.55, 0.85, 0.6, 0.85, 0.55, 0.5, 0.65, 0.65, 0.5, 1.0],\n",
              " [2.0474789142608643,\n",
              "  0.7944716215133667,\n",
              "  1.6055183410644531,\n",
              "  0.14559157192707062,\n",
              "  1.7480700016021729,\n",
              "  1.9151690006256104,\n",
              "  1.5337597131729126,\n",
              "  2.7421457767486572,\n",
              "  2.9256415367126465,\n",
              "  0.02788039669394493])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG_byRL0aI_y",
        "colab_type": "code",
        "outputId": "85529315-86b3-445f-8e48-5698dda1cc1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean_mae=numpy.mean(all_mae_scores)*100\n",
        "std_mae=numpy.std(all_scores)*100\n",
        "print(\"Result: %.2f%% (%.2f%%)\" % (mean_mae, std_mae))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: 58.50% (19.63%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PA0drnjLIS3",
        "colab_type": "code",
        "outputId": "a5fd2770-39fe-4b4e-88a3-b9c97918f396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean_mse=numpy.mean(all_mse_scores)*100\n",
        "std_mse=numpy.std(all_scores)*100\n",
        "print(\"Result: %.2f%% (%.2f%%)\" % (mean_mse, std_mse))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: 92.50% (19.63%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDME6Hw45U1i",
        "colab_type": "code",
        "outputId": "e3faa116-ac4a-481f-d065-c2bda21b3bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numpy.mean(all_mae_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.66999996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdhvlP0g7qK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}